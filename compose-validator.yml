version: "3.8"

services:
  ipfs:
    container_name: val-ipfs
    image: ipfs/kubo:master-2024-09-29-a178307
    ports:
      - "4001:4001" # ipfs swarm
      - "127.0.0.1:5001:5001" # ipfs api
    #     - "8080:8080" # ipfs gateway
    environment:
      LIBP2P_FORCE_PNET: 1
      LEADER_IPFS_MULTIADDR: ${LEADER_IPFS_MULTIADDR}
      IPFS_SWARM_KEY_FILE: ${IPFS_SWARM_KEY_FILE:-/data/ipfs/swarm.key}
      IS_LEADER: ${IS_LEADER:-false}
      SWARM_SECRET: ${SWARM_SECRET}
    volumes:
      - ipfs-data:/data/ipfs
      - ./ipfs-start.sh:/usr/local/bin/ipfs-start.sh
      # - ./swarm.key:/data/ipfs/swarm.key
    networks:
      - ipfs-network
    entrypoint:
      [
        "/bin/sh",
        "-c",
        "chmod +x /usr/local/bin/ipfs-start.sh && /usr/local/bin/ipfs-start.sh",
      ]
    restart: unless-stopped
    healthcheck:
      interval: 8s

  cluster:
    container_name: val-cluster
    image: ipfs/ipfs-cluster:master-2024-07-16-a5dab45
    depends_on:
      ipfs:
        condition: service_healthy
    environment:
      CLUSTER_PEERNAME: ${CLUSTER_PEERNAME:-val_cluster}
      CLUSTER_SECRET: ${CLUSTER_SECRET}
      CLUSTER_IPFSHTTP_NODEMULTIADDRESS: /dns4/ipfs/tcp/5001
      # CLUSTER_CRDT_TRUSTEDPEERS: "*"
      CLUSTER_RESTAPI_HTTPLISTENMULTIADDRESS: /ip4/0.0.0.0/tcp/9094 # Expose API
      LEADER_IPFS_CLUSTER_MULTIADDR: ${LEADER_IPFS_CLUSTER_MULTIADDR}
      IS_LEADER: ${IS_LEADER:-false}
      # CLUSTER_MONITORPINGINTERVAL: 2s # Speed up peer discovery
    ports:
      # Open API port (allows ipfs-cluster-ctl usage on host)
      - "127.0.0.1:9094:9094"
      # - "9095:9095" # Cluster IPFS Proxy endpoint
      - "9096:9096" # Cluster swarm endpoint
    volumes:
      - ipfs-cluster-data:/data/ipfs-cluster
      - ./cluster-start.sh:/usr/local/bin/cluster-start.sh
    entrypoint: ["/bin/sh", "/usr/local/bin/cluster-start.sh"]
    networks:
      - ipfs-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "ipfs-cluster-ctl", "id"]
      interval: 8s
      timeout: 10s
      retries: 3

  listener:
    container_name: val-listener
    build:
      context: ./ts
    command: sh -c "npx tsx src/listener.ts ${LISTENER_ARGS}"
    environment:
      - LEADER_IPFS_CLUSTER_ID=${LEADER_IPFS_CLUSTER_ID}
    volumes:
      - ipfs-cluster-data:/data/ipfs-cluster
    networks:
      - ipfs-network
    restart: unless-stopped

  inscriber:
    container_name: val-inscriber
    build:
      context: ./ts
    command: sh -c "npx tsx src/inscriber.ts ${INSCRIBER_ARGS}"
    volumes:
      - ${BT_DIR}:/root/.bittensor
    depends_on:
      cluster:
        condition: service_healthy
    networks:
      - ipfs-network
    restart: unless-stopped

  mainnet-lite:
    image: ghcr.io/opentensor/subtensor:latest
    build:
      context: ${SUBTENSOR_PATH:-../subtensor} 
      dockerfile: Dockerfile
      target: subtensor
    cpu_count: 4
    mem_limit: 8G
    memswap_limit: 12G
    ports:
      - "127.0.0.1:9944:9944"
      - "30333:30333"
      # - "9933:9933"
    networks:
      - ipfs-network
    environment:
      - CARGO_HOME=/var/www/node-subtensor/.cargo
    container_name: subtensor-mainnet-lite
    volumes:
      - mainnet-lite-volume:/tmp/blockchain
    command:
      - /bin/bash
      - -c
      - |
        node-subtensor \
          --base-path /tmp/blockchain \
          --chain raw_spec_finney.json \
          --rpc-external --rpc-cors all \
          --no-mdns \
          --in-peers 500 --out-peers 500 \
          --bootnodes /dns/bootnode.finney.chain.opentensor.ai/tcp/30333/ws/p2p/12D3KooWRwbMb85RWnT8DSXSYMWQtuDwh4LJzndoRrTDotTR5gDC \
          --sync warp
    profiles:
      - mainnet-lite
    restart: unless-stopped

networks:
  ipfs-network:

volumes:
  ipfs-data:
  ipfs-cluster-data:
  mainnet-lite-volume:
